# My Reading & Guess

#### 2018.8

1. (2018) **Manifold Mixup: Encouraging Meaningful On-Manifold Interpolation as a Regularizer** (Verma et al.)
    - Guess: The nature of generalization is linearization, and the purpose for performing all kinds of nonlinear transformations is to help the linearity find the underlying space and give a fully play to the talent of the linearity. The nonlinearity is the path but not the destination, since it is the destination for the linearity. When the destination reached, the manifold would fill all the space.
2. (2016) **Progressive Neural Networks** (Rusu et al.)
    - Guess: Multi-paths or multi-braches structures based on extensive skip connections, lateral connections, highways and gates, plus a procedure to actively search and build such structures, by exploiting a more effective and iterative, implicit or explicit attention mechanism, might be one of the way to avoid catastrophic forgetting and interference problem and simultaneously leverage learned and transferred knowledge.
3. (2017) **Measuring the tendency of CNNs to Learn Surface Statistical Regularities** (Jo et al.)
    - Guess: The space of high-level abstraction cannot be learned by using SGD when reaching the first-time convergence, except that only statistical regularities can be captured in this way. This level of abstraction can only be sought in a back-and-forth, twist-and-turns and chaos-and-consciousness process, finally leaving the loop and reaching some enlightment point. That means there cannot be just one objective, one stationary optimization direction.
    - Guess: The training set is just a mirror, but the world the model needs to build should be more than a set of training examples. Therefore, the training set should be used carefully and wisely rather than cursorily and wastefully.
4. (2014) **Intriguing properties of neural networks** (Szegedy et al.)
    - Guess: There is no rose without a thorn. Distributed representation brought in by neural networks causes its powerful expressivity, while I believe it is also one of the reasons for catastrophic forgetting (or the interference problem). The semantic meaning of individual units is handed over to the space spanned by a set of peer units as a collective production. For each inidividual units, there is no such specialization, and everyone is interleaved with each other. I guess it is the current architectures of neural networks that cause the issue. For example, given a fully-connected layer, each unit can receive signals from all units in its previous layer, and send signals to all units in its next layer. The difference between each peer unit is only two layers of weights, one linked from the previous layer, one linked to the next layer. Relying just on this level of difference, one cannot expect that some kind of specialization and modularity will emerge. Therefore, we should rethink the issue of distributed representation, and how we can tap the rose without touching its thorn or being trapped by its tempting offering. Of course, scalar units hold too limited information to develop into a specialized form, so we should consider a new neuron model that can hold rich information filling a subspace and have its own previous and next neurons to interact with, which I guess might bring in a new research direction - neuron attention.
5. (2016) **Transferability in Machine Learning: from Phenomena to Black-Box Attacks using Adversarial Samples** (Papernot et al.)
    - Guess: The intelligence way should not be considered simply as a mathematical optimization problem or pure statistical analysis. First, intelligence is continuous dyniamics, a process between seeking an objetive and pursuing the objective. Therefore, reaching convergence is not the end but a new beginning. I would rather think of the adversarial attack as a way of finding new objetives for machine to extend its "intelligence" to the next level. Second, normal statistical approaches are unconscious, which means it has no drive to learn the data in a more economical way but wastes abundant data to derive some statistical regularities. An intelligent being must do better than that.
